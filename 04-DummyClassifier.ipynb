{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, MinMaxScaler, RobustScaler, Normalizer, LabelEncoder, LabelBinarizer\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "data = pd.read_csv('input_train.csv')\n",
    "label = pd.read_csv('challenge_output_data_training_file_prediction_of_transaction_claims_status.csv', ';')\n",
    "all_data = data.merge(label, left_on='ID', right_on='ID', how='inner').copy()\n",
    "claim_order = sorted(all_data['CLAIM_TYPE'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing Structural Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '3/2017' => 201703\n",
    "temp = all_data['BUYING_DATE'].str.split('/')\n",
    "all_data['BUYING_DATE'] = temp.str[1] + temp.str[0].str.zfill(2)\n",
    "all_data['BUYING_DATE'] = all_data['BUYING_DATE'].astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To improve the Unbalanced Dataset we can delete the missing values for CLAIM_TYPE= '-'\n",
    "all_data = all_data.drop(all_data[(all_data['CLAIM_TYPE']=='-') & (all_data['BUYER_BIRTHDAY_DATE'].isna()) ].index)\n",
    "all_data = all_data.drop(all_data[(all_data['CLAIM_TYPE']=='-') & (all_data['SELLER_SCORE_AVERAGE'].isna()) ].index)\n",
    "all_data = all_data.drop(all_data[(all_data['CLAIM_TYPE']=='-') & (all_data['SHIPPING_MODE'].isna()) ].index)\n",
    "all_data = all_data.drop(all_data[(all_data['CLAIM_TYPE']=='-') & (all_data['SHIPPING_PRICE'].isna()) ].index)\n",
    "all_data = all_data.drop(all_data[(all_data['CLAIM_TYPE']=='-') & (all_data['PRICECLUB_STATUS'].isna()) ].index)\n",
    "all_data = all_data.drop(all_data[(all_data['CLAIM_TYPE']=='-') & (all_data['SELLER_SCORE_COUNT'].isna()) ].index)\n",
    "\n",
    "# Numerical feature \n",
    "all_data['SELLER_SCORE_AVERAGE']=all_data['SELLER_SCORE_AVERAGE'].fillna(-1).values \n",
    "all_data['BUYER_BIRTHDAY_DATE']=all_data['BUYER_BIRTHDAY_DATE'].fillna(-1).values \n",
    "\n",
    "# WARRANTIES_PRICE: There is not missing value but NON_WARRANTIES\n",
    "all_data['WARRANTIES_PRICE']=all_data['WARRANTIES_PRICE'].fillna('NON_WARRANTIES').values \n",
    "\n",
    "# Categorical Features\n",
    "all_data = all_data.fillna('MISSING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Unwanted Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention that missings values = -1\n",
    "all_data = all_data.drop(all_data[(all_data['BUYER_BIRTHDAY_DATE']<1940) & (all_data['BUYER_BIRTHDAY_DATE']>=0)].index)\n",
    "all_data = all_data.drop(all_data[(all_data['BUYER_BIRTHDAY_DATE']>=2000) ].index)\n",
    "all_data = all_data.drop(all_data[(all_data['SELLER_SCORE_AVERAGE']<40) & (all_data['SELLER_SCORE_AVERAGE']>=0)].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['BUYER_BIRTHDAY_DATE']=all_data['BUYER_BIRTHDAY_DATE'].astype(np.int16)\n",
    "all_data['SELLER_SCORE_AVERAGE']=all_data['SELLER_SCORE_AVERAGE'].astype(np.int16)\n",
    "all_data['REGISTRATION_DATE']=all_data['REGISTRATION_DATE'].astype(np.int16)\n",
    "all_data['BUYER_DEPARTMENT']=all_data['BUYER_DEPARTMENT'].astype(np.int16)\n",
    "all_data['SELLER_DEPARTMENT']=all_data['SELLER_DEPARTMENT'].astype(np.int16)\n",
    "all_data['CARD_PAYMENT']=all_data['CARD_PAYMENT'].astype(np.bool)\n",
    "all_data['COUPON_PAYMENT']=all_data['COUPON_PAYMENT'].astype(np.bool)\n",
    "all_data['RSP_PAYMENT']=all_data['RSP_PAYMENT'].astype(np.bool)\n",
    "all_data['WALLET_PAYMENT']=all_data['WALLET_PAYMENT'].astype(np.bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10=all_data['SELLER_COUNTRY'].value_counts().head(10).index\n",
    "all_data.loc[all_data['SELLER_COUNTRY'].isin(top10)==False,'SELLER_COUNTRY'] = 'OTHERS'\n",
    "\n",
    "top10=all_data['SELLER_DEPARTMENT'].value_counts().head(10).index\n",
    "all_data.loc[all_data['SELLER_DEPARTMENT'].isin(top10)==False,'SELLER_DEPARTMENT'] = 'OTHERS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = pd.factorize(all_data['CLAIM_TYPE'])\n",
    "target_number=factor[0]\n",
    "target_label = factor[1]\n",
    "target_vectoriser=np.vectorize(dict(zip(range(8),target_label)).get)\n",
    "lb=LabelBinarizer()\n",
    "\n",
    "####### Nominal #######\n",
    "all_data = pd.concat([all_data,\n",
    "                                pd.get_dummies(all_data['SHIPPING_MODE'], prefix='SHIPPING_MODE'),\n",
    "                                pd.get_dummies(all_data['SELLER_COUNTRY'], prefix='SELLER_COUNTRY'),\n",
    "                                pd.get_dummies(all_data['PRODUCT_TYPE'], prefix='PRODUCT_TYPE'),\n",
    "                                pd.get_dummies(all_data['PRODUCT_FAMILY'], prefix='PRODUCT_FAMILY'),\n",
    "                                pd.get_dummies(all_data['BUYER_DEPARTMENT'], prefix='BUYER_DEPARTMENT'),\n",
    "                                pd.get_dummies(all_data['SELLER_DEPARTMENT'], prefix='SELLER_DEPARTMENT')\n",
    "                           ],\n",
    "                          axis=1)\n",
    "\n",
    "#######Ordinal #######\n",
    "all_data['PRICECLUB_STATUS'] = all_data['PRICECLUB_STATUS'].map( {'MISSING':0,'UNSUBSCRIBED':1, 'REGULAR': 2, 'SILVER':3, 'GOLD':4, 'PLATINUM':5}).astype(np.int16)\n",
    "all_data['SHIPPING_PRICE'] = all_data['SHIPPING_PRICE'].map( {'MISSING':0,'<1':1, '1<5': 2, '5<10':3, '10<20':4, '>20':5}).astype(np.int16)\n",
    "all_data['WARRANTIES_PRICE'] = all_data['WARRANTIES_PRICE'].map( {'NON_WARRANTIES':0, '<5':1, '5<20': 2, '20<50':3, '50<100':4, '100<500':5}).astype(np.int16)\n",
    "all_data['PURCHASE_COUNT'] = all_data['PURCHASE_COUNT'].map( {'<5':1, '5<20': 2, '20<50':3, '50<100':4, '100<500':5, '>500':6}).astype(np.int16)\n",
    "all_data['SELLER_SCORE_COUNT'] = all_data['SELLER_SCORE_COUNT'].map( {'MISSING':0,'<100':1, '100<1000': 2, '1000<10000':3, '10000<100000':4, '100000<1000000':5}).astype(np.int16)\n",
    "all_data['ITEM_PRICE'] = all_data['ITEM_PRICE'].map( {'<10':0, '10<20': 1, '20<50':2, '50<100':3, '100<500':4, '500<1000':5, '1000<5000':6, '>5000':7}).astype(np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Unused Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVAL OF UNUSEFUL FEATURES\n",
    "all_data = all_data.drop([\"ID\"], axis=1)\n",
    "all_data = all_data.drop([\"CLAIM_TYPE\"], axis=1)\n",
    "all_data = all_data.drop(['WARRANTIES_FLG'],  axis=1)\n",
    "\n",
    "# REMOVAL OF FEATURES THAT WERE ENCODED\n",
    "all_data = all_data.drop(['SHIPPING_MODE'],  axis=1)\n",
    "all_data = all_data.drop(['SELLER_COUNTRY'],  axis=1)\n",
    "all_data = all_data.drop(['PRODUCT_FAMILY'],  axis=1)\n",
    "all_data = all_data.drop(['PRODUCT_TYPE'],  axis=1)\n",
    "all_data = all_data.drop(['BUYER_DEPARTMENT'],  axis=1)\n",
    "all_data = all_data.drop(['SELLER_DEPARTMENT'],  axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:       0.18276644324976862 \n",
      "\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                       -       0.25      0.25      0.25      3059\n",
      "                 DAMAGED       0.09      0.09      0.09      1159\n",
      "               DIFFERENT       0.08      0.08      0.08       836\n",
      "                    FAKE       0.00      0.00      0.00        24\n",
      "            NOT_RECEIVED       0.22      0.22      0.22      2831\n",
      "SELLER_CANCEL_POSTERIORI       0.22      0.22      0.22      2698\n",
      "               UNDEFINED       0.05      0.05      0.05       790\n",
      "              WITHDRAWAL       0.11      0.11      0.11      1365\n",
      "\n",
      "             avg / total       0.18      0.18      0.18     12762\n",
      "\n",
      "Wall time: 5.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "numerical_features=list()\n",
    "for x in ['REGISTRATION_DATE','BUYER_BIRTHDAY_DATE','BUYING_DATE','SELLER_SCORE_AVERAGE', 'PRICECLUB_STATUS', 'SHIPPING_PRICE', 'WARRANTIES_PRICE', 'PURCHASE_COUNT', 'SELLER_SCORE_COUNT', 'ITEM_PRICE'] : \n",
    "    numerical_features.append(all_data.columns.get_loc(x))\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data.values, target_number, test_size=0.20, random_state=0, stratify=target_number)\n",
    "w=compute_sample_weight(class_weight='balanced', y=y_train) \n",
    "imputer = Imputer(strategy='mean', missing_values=-1) \n",
    "\n",
    "#fill of NaN\n",
    "imputer.fit(X_train)\n",
    "X_train_imputed = imputer.transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_transformed = X_train_imputed\n",
    "X_train_transformed[:,numerical_features] = scaler.fit_transform(X_train_imputed[:,numerical_features])\n",
    "X_test_transformed = X_test\n",
    "X_test_transformed[:,numerical_features] = scaler.transform(X_test_imputed[:,numerical_features])\n",
    "\n",
    "classifier =  DummyClassifier(strategy='stratified', random_state=0)\n",
    "classifier.fit(X_train_transformed, y_train)\n",
    "y_test_predicted = classifier.predict(X_test_transformed)\n",
    "\n",
    "y_test_predicted_label = target_vectoriser(y_test_predicted)\n",
    "y_test_label = target_vectoriser(y_test)\n",
    "    \n",
    "print('f1_score:      ',metrics.f1_score(y_test, y_test_predicted, average='weighted'), '\\n')\n",
    "print(classification_report(y_test_label, y_test_predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:       0.14286622651198197 \n",
      "\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                       -       0.24      0.12      0.16      3059\n",
      "                 DAMAGED       0.08      0.11      0.10      1159\n",
      "               DIFFERENT       0.07      0.13      0.09       836\n",
      "                    FAKE       0.00      0.25      0.01        24\n",
      "            NOT_RECEIVED       0.24      0.13      0.17      2831\n",
      "SELLER_CANCEL_POSTERIORI       0.22      0.13      0.16      2698\n",
      "               UNDEFINED       0.06      0.12      0.08       790\n",
      "              WITHDRAWAL       0.11      0.13      0.12      1365\n",
      "\n",
      "             avg / total       0.18      0.13      0.14     12762\n",
      "\n",
      "Wall time: 5.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "numerical_features=list()\n",
    "for x in ['REGISTRATION_DATE','BUYER_BIRTHDAY_DATE','BUYING_DATE','SELLER_SCORE_AVERAGE', 'PRICECLUB_STATUS', 'SHIPPING_PRICE', 'WARRANTIES_PRICE', 'PURCHASE_COUNT', 'SELLER_SCORE_COUNT', 'ITEM_PRICE'] : \n",
    "    numerical_features.append(all_data.columns.get_loc(x))\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data.values, target_number, test_size=0.20, random_state=0, stratify=target_number)\n",
    "w=compute_sample_weight(class_weight='balanced', y=y_train) \n",
    "imputer = Imputer(strategy='mean', missing_values=-1) \n",
    "\n",
    "#fill of NaN\n",
    "imputer.fit(X_train)\n",
    "X_train_imputed = imputer.transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_transformed = X_train_imputed\n",
    "X_train_transformed[:,numerical_features] = scaler.fit_transform(X_train_imputed[:,numerical_features])\n",
    "X_test_transformed = X_test\n",
    "X_test_transformed[:,numerical_features] = scaler.transform(X_test_imputed[:,numerical_features])\n",
    "\n",
    "classifier =  DummyClassifier(strategy='stratified', random_state=0)\n",
    "classifier.fit(X_train_transformed, y_train, sample_weight=w)\n",
    "y_test_predicted = classifier.predict(X_test_transformed)\n",
    "\n",
    "y_test_predicted_label = target_vectoriser(y_test_predicted)\n",
    "y_test_label = target_vectoriser(y_test)\n",
    "    \n",
    "print('f1_score:      ',metrics.f1_score(y_test, y_test_predicted, average='weighted'), '\\n')\n",
    "print(classification_report(y_test_label, y_test_predicted_label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
